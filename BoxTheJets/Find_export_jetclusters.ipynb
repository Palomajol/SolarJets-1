{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646ffb5b-3b92-474b-a044-be16533ca1de",
   "metadata": {},
   "source": [
    "# Making Jet clusters and exporting them\n",
    "## Need Aggregator files, SOL_Tc_stats (or T3) and subjects_Tc (or T3) made during the aggregation in BoxTheJets\n",
    "This notebook takes the jets detected per subjects and looks for clusters in space and time. If two jets of different clusters fall within the epsilon given by the user (set by eps and time_eps) they are clustered together to make a jet cluster, this can be repeated such that more jets are added to the cluster. Clusters can only contain one jet per subject such that closeby jets are detected seperatly. \n",
    "The second part of this notebook requires the database of the Zooniverse to make the conversion between pixels ans solar coordinates. For now this can only be done on the foxsiaadmins computer of Minnesota University. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fba1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from aggregation import Aggregator, get_subject_image\n",
    "from aggregation import SOL\n",
    "from aggregation import json_export_list\n",
    "from aggregation import get_box_edges, sigma_shape\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.dates import DateFormatter\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7efb1-6edc-4df3-b571-7bc51b051db9",
   "metadata": {},
   "source": [
    "Read in the data made by the aggregation steps. This analysis can also be done using the SOL_T3_stats and subjects_T3 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = Aggregator('reductions/point_reducer_hdbscan_box_the_jets.csv', \n",
    "                        'reductions/shape_reducer_dbscan_box_the_jets.csv')\n",
    "aggregator.load_extractor_data('extracts/point_extractor_by_frame_box_the_jets.csv',\n",
    "                               'extracts/shape_extractor_rotateRectangle_box_the_jets.csv')\n",
    "sol = SOL('../SOL_Tc_stats.csv', aggregator) \n",
    "\n",
    "SOL_small,SOL_subjects,filenames0,times,Num,start,end,notes=np.loadtxt('../SOL_{}_stats.csv'.format('Tc'),delimiter=',',unpack=True,dtype=str)\n",
    "Num=Num.astype(float)\n",
    "\n",
    "subjects,date,end_date,ans,agreement,subject_file, subject_sol=np.loadtxt('../subjects_{}.csv'.format('Tc'),delimiter=',',unpack=True,dtype=str)\n",
    "date=np.array(date,dtype='datetime64')\n",
    "end_date=np.array(end_date,dtype='datetime64')\n",
    "subjects=subjects.astype(int)\n",
    "agreement=agreement.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f53a5-3e87-47a2-98b1-8acd62995222",
   "metadata": {},
   "source": [
    "### Start the Jet clustering, we picked the variabels eps= 3.0 and time_eps = 2.0. This was done based on looking at the results.  \n",
    "The epsilon voor space clustering is chosen to be 3, however in some cases with a small viewpoint this can still be quite large. Since the smallest distance is chosen for clustering this often does not interfer with good results\n",
    "The time epsilon meant a jet that was 'missing' in one subject could still be detected if it was present in the next subject. This can mean rapidly reoccuring jets can be clustered together unintensionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338342a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Jet_clusters=np.array([])\n",
    "#Set the space and time epsilon\n",
    "eps,time_eps=3.0,2.0\n",
    "\n",
    "for s in range(len(SOL_small)):\n",
    "    del_index=np.array([],dtype=int)\n",
    "    SOL_event=SOL_small[s]\n",
    "    print(f'SOL_small[{s}] ', SOL_event)\n",
    "    try:\n",
    "        clusters, distance_met, point_met, box_met = sol.filter_jet_clusters(SOL_event, eps=eps, time_eps=time_eps)\n",
    "    except:\n",
    "        print(f\"No jets in {SOL_event}\")\n",
    "        continue\n",
    "    for j, cluster in enumerate(clusters):\n",
    "        print(j, len(cluster.jets))\n",
    "        cluster.adding_new_attr(\"SOL\",SOL_event)\n",
    "        if len(cluster.jets)==1 and ans[subjects==cluster.jets[0].subject][0]=='n':\n",
    "            #jets that only last 1 subject and do not have 50% agreement yes are excluded\n",
    "            del_index=np.append(del_index,j)\n",
    "    if len(del_index)>0:\n",
    "        print(f'Remove {len(del_index)} clusters from list due to too low agreement')\n",
    "        clusters = np.delete(clusters, del_index)        \n",
    "    Jet_clusters=np.append(Jet_clusters,clusters)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd1611-34cf-44f5-9f75-322d4627b59f",
   "metadata": {},
   "source": [
    "### From here on the code will work on the foxsiadmins computer to have access to the visual files of the Zooniverse subjects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6db546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aggregation.image_handler import solar_conversion\n",
    "\n",
    "def get_solar_distance(subject_id,pair):\n",
    "    '''\n",
    "        Get the solar projected distance between the two pairs of X,Y coordinates\n",
    "            Inputs:\n",
    "            -------\n",
    "            subject_id : int\n",
    "                subject_id used in the Zooniverse subject\n",
    "            pair : np.array\n",
    "                x,y Coordinates of the two points 1,2 for which the solar distance needs to be calculated\n",
    "                format [[x1,y1],[x2,y2]]\n",
    "    '''\n",
    "    solw1=solar_conversion(subject_id,pair[0][0],pair[0][1])\n",
    "    solw2=solar_conversion(subject_id,pair[1][0],pair[1][1])\n",
    "    #Euclidean distance\n",
    "    distance=np.sqrt((solw1[0]-solw2[0])**2 +(solw1[1]-solw2[1])**2 )\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ea3f51-20cc-475d-85bd-c0b738e41666",
   "metadata": {},
   "source": [
    "### Go through the list of jet clusters and determine their propeties in physical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3036fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=1\n",
    "\n",
    "for C in Jet_clusters:\n",
    "    print('Jet start')\n",
    "    H=np.array([])\n",
    "    W=np.array([])\n",
    "    X=np.array([])\n",
    "    Y=np.array([])\n",
    "    sig=np.array([])\n",
    "    H_sig=np.zeros((len(C.jets),2))\n",
    "    obs_time=np.array([],dtype='datetime64')\n",
    "    end_time=np.array([],dtype='datetime64')\n",
    "    for j, jet in enumerate(C.jets):\n",
    "        print(j, len(C.jets))\n",
    "        width_pair,height_pair=jet.get_width_height_pairs()\n",
    "        #Find sigma of maximum height by first getting the pixel height\n",
    "        H_pix_box=np.sqrt((height_pair[1][0]-height_pair[0][0])**2 +(height_pair[1][1]-height_pair[0][1])**2 )\n",
    "        index=list(map(int, jet.cluster_values)).index(int(H_pix_box))\n",
    "        #Get the height of the box in pixels for the +-1 sigma\n",
    "        plus_sigma, minus_sigma = sigma_shape(jet.cluster_values, jet.sigma)\n",
    "        H_pix_minus= minus_sigma[index]\n",
    "        H_pix_plus= plus_sigma[index]\n",
    "        #print(width_pair,height_pair)\n",
    "        file=subject_file[subjects==jet.subject][0]\n",
    "        #Get the solar locations on the jet\n",
    "        try:\n",
    "            Bx,By=solar_conversion(jet.subject,jet.start[0],jet.start[1])\n",
    "        except:\n",
    "            print('This one breaks', jet.subject)\n",
    "            continue\n",
    "        Ex,Ey=solar_conversion(jet.subject,jet.end[0],jet.end[1])\n",
    "        print('Start base',Bx,By)\n",
    "        print('sigma',jet.sigma)\n",
    "        #Add as attributes and as a list\n",
    "        jet.adding_new_attr(\"solar_start\",[Bx,By])\n",
    "        jet.adding_new_attr(\"solar_end\",[Ex,Ey])\n",
    "        sig=np.append(sig,jet.sigma)\n",
    "        X=np.append(X,Bx)\n",
    "        Y=np.append(Y,By)\n",
    "        #Get the dates the subjecst were observed\n",
    "        O=date[subjects==jet.subject][0]\n",
    "        obs_time=np.append(obs_time,O)\n",
    "        E=end_date[subjects==jet.subject][0]\n",
    "        end_time=np.append(end_time,E)\n",
    "        #Calculate the height an wisth in arcsec\n",
    "        height=get_solar_distance(jet.subject,height_pair)\n",
    "        width=get_solar_distance(jet.subject,width_pair)\n",
    "        #Add as attributes and list\n",
    "        jet.adding_new_attr(\"solar_H\",height)\n",
    "        jet.adding_new_attr(\"solar_W\",width)\n",
    "        H=np.append(H,height)\n",
    "        W=np.append(W,width)\n",
    "        #Get the error on the height by scaling the height with the (height_sigma/height -1)\n",
    "        err_plus, err_minus = height*(H_pix_plus/H_pix_box-1) , height*(H_pix_minus/H_pix_box-1)\n",
    "        H_sig[j]=np.array([err_plus,err_minus])\n",
    "        jet.adding_new_attr(\"solar_H_sig\",[err_plus,err_minus])\n",
    "    \n",
    "    #duration=(obs_time[-1]-obs_time[0])/np.timedelta64(1, 'm')\n",
    "    duration=(end_time[-1]-obs_time[0])/np.timedelta64(1, 'm')\n",
    "    vel=np.max(H)/((obs_time[np.argmax(H)]-obs_time[0])/ np.timedelta64(1, 's'))\n",
    "    if np.isinf(vel)==True:\n",
    "        vel=np.NaN\n",
    "    \n",
    "    C.adding_new_attr(\"ID\",ID)\n",
    "    C.adding_new_attr('Max_Height', np.max(H))\n",
    "    C.adding_new_attr('std_maxH', H_sig[np.argmax(H)])\n",
    "    C.adding_new_attr(\"Height\",np.average(H))\n",
    "    C.adding_new_attr(\"std_H\",np.std(H))\n",
    "    C.adding_new_attr(\"Width\",np.average(W))\n",
    "    C.adding_new_attr(\"std_W\",np.std(W))\n",
    "    C.adding_new_attr(\"Bx\",np.average(X))\n",
    "    C.adding_new_attr(\"std_Bx\",np.std(X))\n",
    "    C.adding_new_attr(\"By\",np.average(Y))\n",
    "    C.adding_new_attr(\"std_By\",np.std(Y))\n",
    "    C.adding_new_attr(\"obs_time\",obs_time[0])\n",
    "    C.adding_new_attr(\"sigma\",np.average(sig))\n",
    "    C.adding_new_attr(\"Duration\",duration)\n",
    "    C.adding_new_attr(\"Velocity\",vel)\n",
    "    \n",
    "    ID+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88add389-7feb-4bba-9efa-f05d53d459dc",
   "metadata": {},
   "source": [
    "### Add the longitude and latitude of the measured basepoints as properties to the Jet_cluster objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import sunpy.map\n",
    "from sunpy.coordinates import frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in Jet_clusters:\n",
    "    #print(C.Bx,C.By)\n",
    "    X,Y=C.Bx,C.By\n",
    "    sky_coord = SkyCoord(X*u.arcsec, Y*u.arcsec, frame=frames.Helioprojective(observer=\"earth\", \n",
    "                                                                               obstime=str(C.obs_time)))\n",
    "    #print(sky_coord.heliographic_stonyhurst)\n",
    "    Coord=sky_coord.heliographic_stonyhurst\n",
    "    if np.isnan(Coord.lat):\n",
    "        print('Coordinates off limb')\n",
    "        with frames.Helioprojective.assume_spherical_screen(sky_coord.observer):\n",
    "            print(sky_coord.heliographic_stonyhurst)\n",
    "            Coord=sky_coord.heliographic_stonyhurst\n",
    "            C.adding_new_attr(\"Lat\",float(str(Coord.lat).split('d')[0]))\n",
    "            C.adding_new_attr(\"Lon\",float(str(Coord.lon).split('d')[0]))\n",
    "\n",
    "    else:\n",
    "        C.adding_new_attr(\"Lat\",float(str(Coord.lat).split('d')[0]))\n",
    "        C.adding_new_attr(\"Lon\",float(str(Coord.lon).split('d')[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2e8776",
   "metadata": {},
   "source": [
    "## Export the results of the clustering\n",
    "Export the JetCluster objects to a JSON file\n",
    "or \n",
    "Export the results to a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jet_clusters_trimmed=Jet_clusters\n",
    "d=0\n",
    "for i,C in enumerate(Jet_clusters):\n",
    "    for jet in C.jets:\n",
    "        try:\n",
    "            T=jet.solar_H\n",
    "            #Jet_clusters_trimmed=np.append(Jet_clusters_trimmed,C)\n",
    "        except:\n",
    "            print(jet.subject,i,'Did not work')\n",
    "            #Jet_clusters_trimmed=np.delete(Jet_clusters_trimmed,i)\n",
    "            d+=1\n",
    "#print(len(Jet_clusters),len(Jet_clusters_trimmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd34f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jet_clusters_trimmed=np.delete(Jet_clusters,[409,426])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b28794",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_export_list(Jet_clusters_trimmed,f'exports/Jet_clusters_{eps}_{time_eps}_paper') #Export all the JetCluster objects\n",
    "#Jet_clusters[0].json_export('output_single') #Export a single JetCluster object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster_date = np.array([Jet_clusters[i].obs_time for i in range(len(Jet_clusters))],dtype=str)\n",
    "Cluster_SOL= np.array([Jet_clusters[i].SOL for i in range(len(Jet_clusters))],dtype=str)\n",
    "stat_Bx = np.array([Jet_clusters[i].Bx for i in range(len(Jet_clusters))],dtype=str)\n",
    "stat_By = np.array([Jet_clusters[i].By for i in range(len(Jet_clusters))],dtype=str)\n",
    "stat_Lon = np.array([Jet_clusters[i].Lon for i in range(len(Jet_clusters))],dtype=str)\n",
    "stat_Lat = np.array([Jet_clusters[i].Lat for i in range(len(Jet_clusters))],dtype=str)\n",
    "stat_H = np.array([Jet_clusters[i].Max_Height for i in range(len(Jet_clusters))],dtype=str)\n",
    "stat_W = np.array([Jet_clusters[i].Width for i in range(len(Jet_clusters))],dtype=str)\n",
    "stat_dur = np.array([Jet_clusters[i].Duration for i in range(len(Jet_clusters))],dtype=str)\n",
    "stat_vel = np.array([Jet_clusters[i].Velocity for i in range(len(Jet_clusters))],dtype=str)\n",
    "stat_sigma = np.array([Jet_clusters[i].sigma for i in range(len(Jet_clusters))],dtype=str)\n",
    "std_H= np.array([Jet_clusters[i].std_maxH for i in range(len(Jet_clusters))],dtype=str)\n",
    "std_W= np.array([Jet_clusters[i].std_W for i in range(len(Jet_clusters))],dtype=str)\n",
    "std_Bx= np.array([Jet_clusters[i].std_Bx for i in range(len(Jet_clusters))],dtype=str)\n",
    "std_By= np.array([Jet_clusters[i].std_By for i in range(len(Jet_clusters))],dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce57c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open(f'exports/Jet_clusters_{eps}_{time_eps}_paper.csv','w')\n",
    "csvfile.writelines('#date, SOL_event, duration, basepoint_X, std_X, basepoint_Y, std_Y, basepoint_X_longitude, basepoint_Y_latitude, max_height, upper_H, lower_H, avg_width, std_width, velocity, sigma')\n",
    "csvfile.writelines('\\n')\n",
    "with open(f'exports/Jet_clusters_{eps}_{time_eps}_test.csv','a') as csvfile:\n",
    "    np.savetxt(csvfile, np.column_stack((Cluster_date,Cluster_SOL,stat_dur,stat_Bx,std_Bx,stat_By,std_By,stat_Lon,stat_Lat,stat_H,std_H,stat_W,std_W,stat_vel,stat_sigma)), delimiter=\",\",newline='\\n',fmt='%s')\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788a472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
